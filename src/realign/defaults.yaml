tools:
  get_current_weather:
    type: function
    function:
      name: get_current_weather
      description: Get the current weather in a given location
      parameters:
        type: object
        properties:
          location:
            type: string
            description: The city and state, e.g. San Francisco, CA
          unit:
            type: string
            enum: [celsius, fahrenheit]
        required: [location, unit]

  google_flights:
    type: function
    function:
      name: google_flights
      description: Get flights from one airport to another
      parameters:
        type: object
        properties:
          departure_id:
            type: string
            description: The departure airport IATA code
          arrival_id:
            type: string
            description: The arrival airport IATA code
          outbound_date:
            type: string
            description: The outbound date in YYYY-MM-DD format
          return_date:
            type: string
            description: The return date in YYYY-MM-DD format
        required: [departure_id, arrival_id, outbound_date, return_date]
  
  google_search:
    type: function
    function:
      name: google_search
      description: Search the web using Google search
      parameters:
        type: object
        properties:
          q:
            type: string
            description: The search query
        required: [q]

  get_website_text:
    type: function
    function:
      name: get_website_text
      description: Get the text of a given website URL
      parameters:
        type: object
        properties:
          url:
            type: string
            description: The URL of the website
        required: [url]

  
  current_date:
    type: function
    function:
      name: current_date
      description: Get the current date in YYYY-MM-DD        

llm_agents:
  default: &basic_agent_settings
    model: openai/gpt-4o-mini
    system_prompt: |
      Be a good agent.

  rating_5_star_agent: &rating_5_star_agent
    model: openai/gpt-4o-mini
    template: rating_5_star
    json_mode: on
    hyperparams:
      temperature: 0

  explanation_summary_agent: &explanation_summary_agent
    model: openai/gpt-4o-mini
    template: explanation_summary
    json_mode: on
    hyperparams:
      temperature: 0

  summary_agent: &summary_agent
    model: openai/gpt-4o-mini
    template: summary
    json_mode: on
    hyperparams:
      temperature: 0

  pairwise_judge_agent: &pairwise_judge_agent
    model: openai/gpt-4o-mini
    template: |
      Based on the given criteria and {{ choices | length }} choices, rank them in order, starting with the choice that fits the criteria best, and ending the choice that fits the criteria worst. 
      
      Finally, respond in JSON format {"best_choice": "2", "worst_choice": "1"} with your best and worst choices. For example, if the choice 3 is the best choice and choice 5 is the worst, respond {"best_choice": "3", "worst_choice": "5"}.

      [Criteria]
      {{ criteria }}

      {% for choice in choices %}
          [Choice {{ loop.index }}]
          {{ choice }}
      {% endfor %}

      [Selection]
    json_mode: on
    hyperparams:
      temperature: 0

evaluators:

  # hf
  hf_pipeline: 
  hf_label_score_aggregator:

  hf_hate_speech:
    wraps: hf_pipeline
    task: text-classification
    model: facebook/roberta-hate-speech-dynabench-r4-target

    checker: value['label'] in target
    target: [nothate]
    asserts: off

  hf_sentiment_classifier:
    wraps: hf_pipeline
    task: text-classification
    model: cardiffnlp/twitter-roberta-base-sentiment-latest

    checker: value['label'] in target
    target: [positive, neutral]
    asserts: off

  # checkers
  numrange:

  # llm
  allm_rating_json:
    repeat: 3
    aggregate: allm_rating_json_aggregate
    agent_settings: *rating_5_star_agent

  allm_pairwise_judge:
    batch_size: 2
    agent_settings: *pairwise_judge_agent

  allm_rating_json_aggregate:

  # rag
  ragas_pipeline:

  ragas_faithfulness:
    wraps: ragas_pipeline
    metrics: faithfulness

  ragas_answer_relevancy:
    wraps: ragas_pipeline
    metrics: answer_relevancy

  ragas_context_precision:
    wraps: ragas_pipeline
    metrics: context_precision

  ragas_context_recall:
    wraps: ragas_pipeline
    metrics: context_recall

  ragas_context_entity_recall:
    wraps: ragas_pipeline
    metrics: context_entity_recall
  
  ragas_noise_sensitivity_relevant:
    wraps: ragas_pipeline
    metrics: noise_sensitivity_relevant

  ragas_noise_sensitivity_irrelevant:
    wraps: ragas_pipeline
    metrics: noise_sensitivity_irrelevant

  ragas_answer_similarity:
    wraps: ragas_pipeline
    metrics: answer_similarity
  
  ragas_answer_correctness:
    wraps: ragas_pipeline
    metrics: answer_correctness

  ragas_reference_free_rubrics_score:
    wraps: ragas_pipeline
    metrics: reference_free_rubrics_score

  ragas_labelled_rubrics_score:
    wraps: ragas_pipeline
    metrics: labelled_rubrics_score

  ragas_summarization_score:
    wraps: ragas_pipeline
    metrics: summarization_score

  # nlp
  word_count:
  character_count:
  token_count:
  chat_word_count_by_role:
  levenshtein_distance:
  cosine_similarity:
  keyword_assertion:

  # stats
  weighted_sum:
  weighted_mean:

  elo_ratings:
    initial_rating: 1500
    k_factor: 32

